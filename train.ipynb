{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape code snippets from GeeksforGeeks page in batches\n",
    "def scrape_gfg_code_batch(url_list, batch_size):\n",
    "    all_code_snippets = []  # Initialize list to store all code snippets\n",
    "    \n",
    "    # Regular expression pattern to match comments containing the phrase 'This code is contributed by'\n",
    "    contributed_comment_pattern = r'#.*?This code is contributed by.*?$'\n",
    "    \n",
    "    # Iterate over URL list in batches\n",
    "    for i in range(0, len(url_list), batch_size):\n",
    "        batch_urls = url_list[i:i+batch_size]  # Get batch of URLs\n",
    "        \n",
    "        # Iterate over URLs in the batch\n",
    "        for url in batch_urls:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            code_containers = soup.find_all('div', {'class': 'code-container'})\n",
    "            # Extract code snippets from current URL\n",
    "            code_snippets = []\n",
    "            for container in code_containers:\n",
    "                # Remove comments containing the phrase 'This code is contributed by'\n",
    "                code_snippet = re.sub(contributed_comment_pattern, '', container.text.strip(), flags=re.MULTILINE)\n",
    "                code_snippets.append(code_snippet)\n",
    "                \n",
    "                # Save the code snippet to a text file\n",
    "                with open('code_snippets.txt', 'a', encoding='utf-8') as file:\n",
    "                    file.write(code_snippet)\n",
    "                    file.write('\\n\\n')  # Add a newline between snippets\n",
    "            \n",
    "            # Append code snippets to the list\n",
    "            all_code_snippets.extend(code_snippets)\n",
    "    \n",
    "    return all_code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls = ['https://www.geeksforgeeks.org/maximum-of-two-numbers-in-python/','https://www.geeksforgeeks.org/python-program-to-find-sum-of-array/']\n",
    "urls = ['https://www.geeksforgeeks.org/maximum-of-two-numbers-in-python/']\n",
    "# Batch size for scraping\n",
    "batch_size = 4\n",
    "\n",
    "# Call the scrape_gfg_code_batch function with the URL list and batch size\n",
    "code_snippets = scrape_gfg_code_batch(urls, batch_size)\n",
    "\n",
    "# Print the dictionary containing code snippets with processed URLs as keys\n",
    "for key, code_snippets in code_snippets.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    for code_snippet in code_snippets:\n",
    "        print(code_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data preparation\n",
    "training_data = '\\n'.join(code_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', max_length=2000)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', max_length=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training data\n",
    "input_ids = tokenizer.encode(training_data, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the GPT-2 model\n",
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "for epoch in range(75):  # You can adjust the number of epochs as needed\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('fine_tuned_gpt2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model with output_hidden_states=True\n",
    "model = GPT2LMHeadModel.from_pretrained('fine_tuned_gpt2_model', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tokenizer from the model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt\n",
    "prompt1 = \"Write a program to find the maximum of two numbers in python?\"\n",
    "prompt2 = \"Write a program to find the sum of array in python?\"\n",
    "prompt3 = \"Write a program to find the length of a list in python?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the prompt\n",
    "input_ids = tokenizer.encode(prompt1, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and print the generated code snippet\n",
    "generated_code = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
