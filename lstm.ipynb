{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape code snippets from GeeksforGeeks page in batches\n",
    "def scrape_gfg_code_batch(url_list, batch_size):\n",
    "    all_code_snippets = []  # Initialize list to store all code snippets\n",
    "    \n",
    "    # Regular expression pattern to match comments containing the phrase 'This code is contributed by'\n",
    "    contributed_comment_pattern = r'#.*?This code is contributed by.*?$'\n",
    "    \n",
    "    # Iterate over URL list in batches\n",
    "    for i in range(0, len(url_list), batch_size):\n",
    "        batch_urls = url_list[i:i+batch_size]  # Get batch of URLs\n",
    "        \n",
    "        # Iterate over URLs in the batch\n",
    "        for url in batch_urls:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            code_containers = soup.find_all('div', {'class': 'code-container'})\n",
    "            # Extract code snippets from current URL\n",
    "            code_snippets = []\n",
    "            for container in code_containers:\n",
    "                # Remove comments containing the phrase 'This code is contributed by'\n",
    "                code_snippet = re.sub(contributed_comment_pattern, '', container.text.strip(), flags=re.MULTILINE)\n",
    "                code_snippets.append(code_snippet)\n",
    "            # Append code snippets to the list\n",
    "            all_code_snippets.extend(code_snippets)\n",
    "    \n",
    "    return all_code_snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to scrape code snippets from\n",
    "urls = ['https://www.geeksforgeeks.org/python-basics/', 'https://www.geeksforgeeks.org/python-string/', 'https://www.geeksforgeeks.org/python-lists/']\n",
    "\n",
    "# Batch size for scraping\n",
    "batch_size = 2\n",
    "\n",
    "# Call the scrape_gfg_code_batch function with the URL list and batch size\n",
    "code_snippets = scrape_gfg_code_batch(urls, batch_size)\n",
    "print(code_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize code snippets\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(code_snippets)\n",
    "code_snippets_seq = tokenizer.texts_to_sequences(code_snippets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_len = max([len(seq) for seq in code_snippets_seq])\n",
    "code_snippets_seq = pad_sequences(code_snippets_seq, maxlen=max_sequence_len, padding='post')\n",
    "\n",
    "# Define model architecture\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Plus 1 for padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_len))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(LSTM(64,activation=\"softmax\"))\n",
    "model.add(Dense(max_sequence_len, activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='kullback_leibler_divergence', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(code_snippets_seq, code_snippets_seq, epochs=350, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model.save('lstm_code_generation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate output based on prompt\n",
    "def generate_output(model, tokenizer, prompt_text, max_output_length=100):\n",
    "    # Tokenize and pad the prompt text\n",
    "    prompt_sequence = tokenizer.texts_to_sequences([prompt_text])\n",
    "    prompt_sequence_padded = pad_sequences(prompt_sequence, maxlen=max_sequence_len, padding='post')\n",
    "    \n",
    "    # Generate output sequence using the model\n",
    "    output_sequence = model.predict(prompt_sequence_padded)\n",
    "    print(output_sequence)\n",
    "    # Decode the output sequence\n",
    "    generated_output = tokenizer.sequences_to_texts(output_sequence)[0]\n",
    "    print(generated_output)\n",
    "    return generated_output\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Write a Python function to add two numbers.\"\n",
    "\n",
    "# Generate output based on the prompt\n",
    "generated_output = generate_output(model, tokenizer, prompt)\n",
    "\n",
    "# Print the generated output\n",
    "print(\"Generated Python code based on the prompt:\")\n",
    "print(generated_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
